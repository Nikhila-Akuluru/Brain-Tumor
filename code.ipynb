{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EYRGcLG4lS3E"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "np.random.seed(1337)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(''):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SR9TtCimsaiz"
   },
   "outputs": [],
   "source": [
    "#rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dnlPMgzKnRWW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import pathlib\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jm7KldpPn0NO",
    "outputId": "65e1195e-1eaf-422e-f3ed-7696cc55adbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\content\\sample_data\\Training\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "path_test = '/content/sample_data/Testing'\n",
    "path_data = '/content/sample_data/Training'\n",
    "\n",
    "\n",
    "path_test = pathlib.Path(path_test)\n",
    "path_data = pathlib.Path(path_data)\n",
    "print(path_data)\n",
    "\n",
    "image_count = len(list(path_data.glob('*/*.jpg')))\n",
    "print(image_count)\n",
    "test_image_count = len(list(path_test.glob('*/*.jpg')))\n",
    "print(test_image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WhNtlFeQoR5E"
   },
   "outputs": [],
   "source": [
    "batch = 32\n",
    "img_height = 250\n",
    "img_width = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pz8aG1YkoUi1",
    "outputId": "25daa295-b6a3-4bae-cb0f-ba32d18908f5"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.preprocessing' has no attribute 'image_dataset_from_directory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-980b179a83df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpath_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'training'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.preprocessing' has no attribute 'image_dataset_from_directory'"
     ]
    }
   ],
   "source": [
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "path_data,\n",
    "validation_split = 0.2,\n",
    "subset = 'training',\n",
    "seed = 42,\n",
    "image_size  =(img_height,img_width),\n",
    "batch_size = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxIDQsMSoVmn",
    "outputId": "ac104fdf-5c2f-40ba-fc49-4013b4de7153"
   },
   "outputs": [],
   "source": [
    "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "path_data,\n",
    "validation_split = 0.2,\n",
    "subset = 'validation',\n",
    "seed = 42,\n",
    "image_size = (img_height,img_width),\n",
    "batch_size = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oF1WYqaooa-7",
    "outputId": "6ea27778-f7e0-447f-d36c-b4a4dfcf3544"
   },
   "outputs": [],
   "source": [
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "path_test,\n",
    "seed = 42,\n",
    "image_size = (img_height,img_width),\n",
    "batch_size = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7S5wo2K3oips",
    "outputId": "5002fa96-779a-4e4b-9157-01be0f6b3c5a"
   },
   "outputs": [],
   "source": [
    "print(train.class_names)\n",
    "print(val.class_names)\n",
    "print(test.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "ZHEHmJ-VolnZ",
    "outputId": "2ac2bf53-7634-401f-9fb3-c47b4596eb53"
   },
   "outputs": [],
   "source": [
    "classes = train.class_names\n",
    "plt.figure(figsize = (10,10))\n",
    "for img,label in train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(img[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(classes[label[i]],\n",
    "                  fontdict = {'fontsize': '19',\n",
    "                              'color': 'white'}\n",
    "                 )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZpGZwKXopAN",
    "outputId": "6918d866-0e8e-4fa5-a0b2-f3e2cc11d192"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcJroXfXorTY"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train = train.prefetch(buffer_size=AUTOTUNE)\n",
    "val = val.prefetch(buffer_size=AUTOTUNE)\n",
    "test = test.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_BdM_H-ouuD",
    "outputId": "34dd5f1a-b213-4d2f-820b-414a5ad281ea"
   },
   "outputs": [],
   "source": [
    "help(test.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5kb8Ax1st44"
   },
   "outputs": [],
   "source": [
    "def prediction_label_comparison(model,test):\n",
    "    #Retrieve a batch of images from the test set\n",
    "    image_batch, label_batch = test.as_numpy_iterator().next()\n",
    "    prediction = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "    # Apply a sigmoid since our model returns logits\n",
    "    predictions = tf.nn.sigmoid(prediction).numpy()\n",
    "\n",
    "    n = 0\n",
    "    predict = []\n",
    "    while n<=(predictions.shape[0]-4):\n",
    "        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n",
    "        n+=4\n",
    "        predict.append(pred)\n",
    "    predict = np.array(predict)\n",
    "\n",
    "    #print('Predictions:\\n',predictions)#.numpy())\n",
    "    print('Labels:\\n', label_batch)\n",
    "    print('Predictions:\\n',predict)\n",
    "    '''\n",
    "    print(predictions.shape)\n",
    "    print(label_batch.shape)\n",
    "    print(predict.shape)\n",
    "    '''\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):\n",
    "      ax = plt.subplot(3, 3, i + 1)\n",
    "      plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "      plt.title(classes[predict[i]],fontdict = {'fontsize': '14',\n",
    "                                  'color': 'white'})\n",
    "      plt.axis(\"off\")\n",
    "    return label_batch , predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJuVppbOs7Lo"
   },
   "outputs": [],
   "source": [
    "def test_tumor(list_test_path,model):\n",
    "    # sunflower_url = 'https://'\n",
    "    # sunflower_path = tf.keras.utils.get_file('name of file', origin=sunflower_url)\n",
    "    for path_name in list_test_path:\n",
    "        test_img_path = path_name\n",
    "\n",
    "\n",
    "        test_image = tf.keras.preprocessing.image.load_img(\n",
    "            test_img_path, target_size=(img_height, img_width)\n",
    "        )\n",
    "        test_array = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "        test_array = tf.expand_dims(test_array, 0) # Create a batch\n",
    "\n",
    "        predictions = model.predict(test_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "        print(\n",
    "            \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "            .format(classes[np.argmax(score)], 100 * np.max(score))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UlLPJbWs9XJ"
   },
   "outputs": [],
   "source": [
    "def csv_builder(path_data,label_names):\n",
    "    df = pd.DataFrame(columns = ['images','labels'])\n",
    "    for name in label_names:\n",
    "        BASE_DIR = str(path_data)+'/'\n",
    "        #train_folder_glioma = BASE_DIR+'glioma_tumor/'\n",
    "        train_folder_name = BASE_DIR+name+'/'\n",
    "\n",
    "        #train_annotation = BASE_DIR+'annotated_train_data/'\n",
    "\n",
    "        files_in_train = sorted(os.listdir(train_folder_name))\n",
    "        #files_in_annotated = sorted(os.listdir(train_annotation))\n",
    "\n",
    "        image_names =[i for i in files_in_train]\n",
    "\n",
    "        \n",
    "        for x in image_names:\n",
    "            df = df.append({'images':train_folder_name+str(x),'labels':name},ignore_index=True)\n",
    "            #df = df.append({'images':str(x),'labels':name},ignore_index=True)\n",
    "\n",
    "        #df['images']=[train_folder_glioma+str(x) for x in image_names]\n",
    "        #df['labels']=[train_annotation+str(x) for x in images]\n",
    "        #pd.to_csv('files_path.csv', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoqR6rT4tIAO"
   },
   "outputs": [],
   "source": [
    "def model_inputs(model2,train,val,test):\n",
    "    num_classes = 4\n",
    "    epochs = 15\n",
    "    model2.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=epochs,\n",
    "        #callbacks = callback,\n",
    "        shuffle=False,\n",
    "        verbose = 0\n",
    "    )\n",
    "    results = model2.evaluate(test)\n",
    "    return results[0],results[1] , model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyxAl9wjtQko"
   },
   "outputs": [],
   "source": [
    "def cross_validation(n_splits,final_csv,test_csv,img_width,img_height,model):\n",
    "    final_loss = 0\n",
    "    final_acc = 0\n",
    "\n",
    "    '''\n",
    "    Seperating a dataframe for testing data\n",
    "    '''\n",
    "    ##\n",
    "    final_csv = final_csv.sample(frac=1)\n",
    "    ##\n",
    "    Y = final_csv[['labels']]\n",
    "    n = len(Y)\n",
    "    kf = KFold(n_splits = 5)\n",
    "    #skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) \n",
    "    idg = ImageDataGenerator(#width_shift_range=0.1,\n",
    "#                          height_shift_range=0.1,\n",
    "#                          zoom_range=0.3,\n",
    "#                          fill_mode='nearest',\n",
    "#                          horizontal_flip = True,\n",
    "                         rescale=1./255)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Performing cross validation...')\n",
    "    test = idg.flow_from_dataframe(test_csv,\n",
    "                                       x_col = \"images\",\n",
    "                                       y_col = \"labels\",\n",
    "                                       class_mode = \"sparse\",\n",
    "                                       shuffle = True,\n",
    "                                      target_size = (img_width,img_height),\n",
    "                                      verbose = 0)#,subset='validation')\n",
    "#     test = tf.keras.preprocessing.image_dataset_from_directory(path_test,\n",
    "#                                                                    seed = 42,\n",
    "#                                                                    image_size = (img_height,img_width),\n",
    "#                                                                    batch_size = 32)\n",
    "    for train_index, val_index in kf.split(np.zeros(n),Y):\n",
    "        training_data = final_csv.iloc[train_index]\n",
    "        validation_data = final_csv.iloc[val_index]\n",
    "        train = idg.flow_from_dataframe(training_data,\n",
    "                                        x_col = \"images\",\n",
    "                                        y_col = \"labels\",\n",
    "                                        class_mode = \"sparse\",\n",
    "                                        shuffle = True,\n",
    "                                        subset='training',\n",
    "                                       target_size = (img_width,img_height),\n",
    "                                       verbose = 0)\n",
    "        val = idg.flow_from_dataframe(validation_data,\n",
    "                                      x_col = \"images\",\n",
    "                                      y_col = \"labels\",\n",
    "                                      class_mode = \"sparse\",\n",
    "                                      shuffle = True,\n",
    "                                     target_size = (img_width,img_height),\n",
    "                                     verbose = 0)\n",
    "        loss,acc,returned_model = model_inputs(model,train,val,test)\n",
    "        final_loss += loss\n",
    "        final_acc += acc\n",
    "    return final_loss/n_splits , final_acc/n_splits , returned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Xq3xTNltmpO"
   },
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "conv_layer_32 = tf.keras.layers.Conv2D(32,(3,3),activation='relu')\n",
    "conv_layer_64 = tf.keras.layers.Conv2D(64,3,activation='relu')\n",
    "conv_layer_16 = tf.keras.layers.Conv2D(16,3,activation='relu')\n",
    "max_pool = tf.keras.layers.MaxPooling2D()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zbOJZG1tpUE"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    normalization_layer,\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    #tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n",
    "    #tf.keras.layers.experimental.preprocessing.RandomCrop(170,170)  \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "SfBkqpEdxpEA",
    "outputId": "fad3364a-b65b-47a0-b022-ced25aa581f8"
   },
   "outputs": [],
   "source": [
    "tumors = []\n",
    "\n",
    "for filename in os.listdir('/content/sample_data/Training/giloma'):\n",
    "      if filename.endswith(\"jpg\"): \n",
    "        tumors.append(\"/content/sample_data/Training/giloma/\"+filename)\n",
    "print(tumors[1])\n",
    "img1 = PIL.Image.open(str(tumors[0]))\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "mxJb-FpPyrA-",
    "outputId": "5165ffcb-6cd8-4b85-d418-39db4aae64e1"
   },
   "outputs": [],
   "source": [
    "not_tumors = []\n",
    "\n",
    "for filename in os.listdir('/content/sample_data/Training/normal'):\n",
    "      if filename.endswith(\"jpg\"): \n",
    "        not_tumors.append(\"/content/sample_data/Training/normal/\"+filename)\n",
    "print(not_tumors[1])\n",
    "img2 = PIL.Image.open(str(not_tumors[0]))\n",
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjjhUsFfzBc1",
    "outputId": "ef0ed476-25c8-423a-dad2-6991800acf93"
   },
   "outputs": [],
   "source": [
    "img_opencv = cv2.imread(str(not_tumors[0]))\n",
    "print(img_opencv.shape)\n",
    "img_opencv1 = cv2.imread(str(tumors[0]))\n",
    "print(img_opencv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WwvaW5Byogn"
   },
   "outputs": [],
   "source": [
    "#not_tumors = list(path_data.glob('no_tumor/*'))\n",
    "#img2 = PIL.Image.open(str(not_tumors[0]))\n",
    "#img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8W3VEy0nxCyW"
   },
   "outputs": [],
   "source": [
    "#tumors = list(path_data.glob('glioma/'))\n",
    "#print(tumors)\n",
    "#print(tumors[1])\n",
    "#img1 = PIL.Image.open(str(tumors[0]))\n",
    "#img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "rZmbALmftsec",
    "outputId": "85e05ee5-8228-4a0c-9385-7ec345628910"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img_opencv)\n",
    "img_array = tf.expand_dims(img_array,0)\n",
    "for i in range(9):\n",
    "  augmented_image = data_augmentation(img_array)\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(augmented_image[0])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQId4lwdl1Yn"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6m0JD3S8zQMv"
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  normalization_layer,\n",
    "  conv_layer_32,\n",
    "  max_pool,\n",
    "  conv_layer_32,\n",
    "  max_pool,\n",
    "  conv_layer_32,\n",
    "  max_pool,\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zFPtTp7zTWA"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bps69qKwzWMY",
    "outputId": "059e28e6-9ba7-4e83-94fc-eac06abd60d7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs= 3,\n",
    "    callbacks = callback,\n",
    "    shuffle=False\n",
    ")\n",
    "eff_epochs = len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "Fny6NDdWzaKl",
    "outputId": "9e05c513-cda2-4886-d500-cf3d65660fb2"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = 10\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(eff_epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n",
    "                              'color': 'white'})\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n",
    "                              'color': 'white'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3x7Uu9Gaz1A0",
    "outputId": "bc3346e6-1fad-4772-c5f6-e9558af72c11"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.save(\"braintumor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42ln7A5uz_5G",
    "outputId": "7f10421d-c439-4636-fb75-8016bc99fe78"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwCqhHEK0MI3",
    "outputId": "4c713e61-f4d9-4b30-8b4f-ff21a9e7216d"
   },
   "outputs": [],
   "source": [
    "list_of_paths = ['/content/sample_data/Testing/giloma/image(12).jpg',\n",
    "                 '/content/sample_data/Testing/meningoma/image(12).jpg',\n",
    "                 '/content/sample_data/Testing/normal/image(17).jpg',\n",
    "                 '/content/sample_data/Testing/pituitary/image(1).jpg']\n",
    "test_tumor(list_of_paths,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFiIZxqY0_TA",
    "outputId": "6cfaee88-4c90-4c7c-ecee-0aa19174750d"
   },
   "outputs": [],
   "source": [
    "labels_entire = []\n",
    "pred_entire = []\n",
    "for image_batch,label_batch in test.as_numpy_iterator():\n",
    "    prediction = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "    # Apply a sigmoid since our model returns logits\n",
    "    predictions = tf.nn.sigmoid(prediction).numpy()\n",
    "\n",
    "    n = 0\n",
    "    predict = []\n",
    "    while n<=(predictions.shape[0]-4):\n",
    "        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n",
    "        n+=4\n",
    "        pred_entire.append(pred)\n",
    "    for el in label_batch:\n",
    "        labels_entire.append(el)\n",
    "pred_entire = np.array(pred_entire)\n",
    "labels_entire = np.array(labels_entire)\n",
    "print(pred_entire)\n",
    "print(labels_entire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuGzGG3H8fIR",
    "outputId": "dd8cc78a-7fc7-4746-a2ce-013d9271ea5b"
   },
   "outputs": [],
   "source": [
    "print(len(pred_entire))\n",
    "print(len(labels_entire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGiHbAFA1FXb",
    "outputId": "e9bd4c6e-bf30-4f19-f1a5-6b4985d26e2c"
   },
   "outputs": [],
   "source": [
    "print(classification_report(labels_entire, pred_entire, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jz-vfkk-JYP8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci4oAEbPMVQ8"
   },
   "source": [
    "MODEL DEPLOYMENT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbUh_PmelZ0F"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Gzw02-2MQ_v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project111.ipynbn",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
